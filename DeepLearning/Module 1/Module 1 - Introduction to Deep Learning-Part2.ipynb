{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3258a83",
   "metadata": {},
   "source": [
    "# TensorFlow/Keras Approach for Binary Classification\n",
    "\n",
    "This section demonstrates how to build, train, and evaluate a simple deep learning model for binary classification using TensorFlow and Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e36b0875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4250 - loss: 0.8410 - val_accuracy: 0.4750 - val_loss: 0.7658\n",
      "Epoch 2/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5359 - loss: 0.7068 - val_accuracy: 0.6000 - val_loss: 0.6762\n",
      "Epoch 3/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6578 - loss: 0.6305 - val_accuracy: 0.6875 - val_loss: 0.6170\n",
      "Epoch 4/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7500 - loss: 0.5720 - val_accuracy: 0.7563 - val_loss: 0.5640\n",
      "Epoch 5/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7969 - loss: 0.5203 - val_accuracy: 0.7937 - val_loss: 0.5167\n",
      "Epoch 6/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8172 - loss: 0.4744 - val_accuracy: 0.8125 - val_loss: 0.4718\n",
      "Epoch 7/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8344 - loss: 0.4325 - val_accuracy: 0.8062 - val_loss: 0.4347\n",
      "Epoch 8/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8469 - loss: 0.3993 - val_accuracy: 0.8062 - val_loss: 0.3996\n",
      "Epoch 9/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8656 - loss: 0.3707 - val_accuracy: 0.8438 - val_loss: 0.3727\n",
      "Epoch 10/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8719 - loss: 0.3499 - val_accuracy: 0.8500 - val_loss: 0.3514\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8450 - loss: 0.4151 \n",
      "Test Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Generate a sample binary classification dataset with 1000 samples and 20 features\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a simple deep learning model using Keras Sequential API\n",
    "keras_binary_classifier = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),  # First hidden layer with 32 units and ReLU activation\n",
    "    Dense(16, activation='relu'),                                   # Second hidden layer with 16 units and ReLU activation\n",
    "    Dense(1, activation='sigmoid')                                  # Output layer with sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model with Adam optimizer and binary cross-entropy loss\n",
    "keras_binary_classifier.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model for 10 epochs with batch size 32, using 20% of training data for validation\n",
    "keras_binary_classifier.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set and print the test accuracy\n",
    "loss, accuracy = keras_binary_classifier.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a9a5eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1000, 20)\n",
      "Example feature vector (first sample):\n",
      "[-0.6693561  -1.49577819 -0.87076638  1.14183093  0.02160555  1.73062972\n",
      " -1.25169805  0.28930464  0.35716259 -0.19681112  0.82927369  0.15485045\n",
      " -0.21997009 -0.73913656  1.80201193  1.63460551 -0.93817985 -1.26733697\n",
      " -1.2763343   1.01664321]\n"
     ]
    }
   ],
   "source": [
    "# The feature set X consists of 20 numerical features for each sample, as generated by make_classification.\n",
    "# Each row in X represents a sample, and each column represents a feature.\n",
    "# The features are synthetic and do not have specific real-world meanings, as they are randomly generated for binary classification tasks.\n",
    "# Typically, in make_classification, some features are informative, some are redundant, and some are noise.\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(\"Example feature vector (first sample):\")\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2eda8732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file size: 7720 bytes (0.007362 MB)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Save the model's state_dict\n",
    "torch.save(torch_binary_classifier.state_dict(), 'torch_binary_classifier.pth')\n",
    "\n",
    "# Print the size of the saved file in bytes and MB\n",
    "size_bytes = os.path.getsize('torch_binary_classifier.pth')\n",
    "size_mb = size_bytes / (1024 * 1024)\n",
    "print(f\"Model file size: {size_bytes} bytes ({size_mb:.6f} MB)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca1e4c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [1. 1. 0. 1. 1.]\n",
      "True labels: [1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l4/f7ythdmn3cxcjm_wvnpqx54r0000gn/T/ipykernel_73377/1476778596.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  recreated_model.load_state_dict(torch.load('torch_binary_classifier.pth'))\n"
     ]
    }
   ],
   "source": [
    "# Recreate the model architecture\n",
    "recreated_model = TorchBinaryClassifier(X_test.shape[1])\n",
    "\n",
    "# Load the saved state_dict\n",
    "recreated_model.load_state_dict(torch.load('torch_binary_classifier.pth'))\n",
    "\n",
    "# Set model to evaluation mode\n",
    "recreated_model.eval()\n",
    "\n",
    "# Run inference on a few test samples\n",
    "# torch.no_grad() is a context manager that disables gradient calculation.\n",
    "# This is useful during inference, as it reduces memory usage and speeds up computations.\n",
    "with torch.no_grad():\n",
    "    sample_inputs = X_test_tensor[:5]  # Select the first 5 test samples as input\n",
    "    outputs = recreated_model(sample_inputs)  # Run the recreated model to get output probabilities\n",
    "    predictions = (outputs > 0.5).float()  # Convert probabilities to binary predictions (threshold at 0.5)\n",
    "    print(\"Predicted labels:\", predictions.squeeze().numpy())  # Print predicted labels for the samples\n",
    "    print(\"True labels:\", y_test_tensor[:5].squeeze().numpy())  # Print true labels for the same samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8951b381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight: torch.Size([32, 20])\n",
      "fc1.bias: torch.Size([32])\n",
      "fc2.weight: torch.Size([16, 32])\n",
      "fc2.bias: torch.Size([16])\n",
      "fc3.weight: torch.Size([1, 16])\n",
      "fc3.bias: torch.Size([1])\n",
      "\n",
      "Explanation:\n",
      "The state_dict contains all learnable parameters of the model (weights and biases) for each layer.\n",
      "- 'fc1.weight': Weights of the first fully connected (Linear) layer (shape: [32, 20])\n",
      "- 'fc1.bias': Biases of the first fully connected layer (shape: [32])\n",
      "- 'fc2.weight': Weights of the second fully connected layer (shape: [16, 32])\n",
      "- 'fc2.bias': Biases of the second fully connected layer (shape: [16])\n",
      "- 'fc3.weight': Weights of the output layer (shape: [1, 16])\n",
      "- 'fc3.bias': Bias of the output layer (shape: [1])\n",
      "Each 'weight' is a matrix that transforms inputs from the previous layer, and each 'bias' is a vector added to the output of the corresponding layer.\n"
     ]
    }
   ],
   "source": [
    "# Print the state_dict of the recreated_model\n",
    "state_dict = recreated_model.state_dict()\n",
    "for param_tensor in state_dict:\n",
    "    print(f\"{param_tensor}: {state_dict[param_tensor].shape}\")\n",
    "\n",
    "print(\"\\nExplanation:\")\n",
    "print(\"The state_dict contains all learnable parameters of the model (weights and biases) for each layer.\")\n",
    "print(\"- 'fc1.weight': Weights of the first fully connected (Linear) layer (shape: [32, 20])\")\n",
    "print(\"- 'fc1.bias': Biases of the first fully connected layer (shape: [32])\")\n",
    "print(\"- 'fc2.weight': Weights of the second fully connected layer (shape: [16, 32])\")\n",
    "print(\"- 'fc2.bias': Biases of the second fully connected layer (shape: [16])\")\n",
    "print(\"- 'fc3.weight': Weights of the output layer (shape: [1, 16])\")\n",
    "print(\"- 'fc3.bias': Bias of the output layer (shape: [1])\")\n",
    "print(\"Each 'weight' is a matrix that transforms inputs from the previous layer, and each 'bias' is a vector added to the output of the corresponding layer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cb783d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight: tensor([[-4.5171e-05,  4.6646e-03, -9.8214e-02, -1.6041e-01, -2.9317e-01,\n",
      "         -1.4571e-01,  1.2863e-01,  7.2176e-02, -1.8728e-01,  7.6353e-02,\n",
      "         -1.6650e-02, -2.9129e-01,  1.2376e-02, -1.4162e-01,  1.5673e-01,\n",
      "          2.6968e-01,  1.1151e-01,  2.4467e-02,  1.5969e-01,  2.1049e-01],\n",
      "        [-2.5328e-01, -6.1873e-02, -5.1968e-02,  6.6241e-02, -1.4882e-02,\n",
      "         -1.4669e-01,  3.6497e-03,  8.5239e-03,  8.1167e-02,  1.4268e-01,\n",
      "          9.1777e-02,  8.7566e-02, -1.1516e-01, -2.7174e-02,  2.9731e-01,\n",
      "         -2.4536e-01,  1.6482e-02,  1.3655e-01,  1.4651e-01,  5.5287e-02],\n",
      "        [ 1.0175e-01, -2.8811e-01,  6.9915e-02, -8.3768e-02, -2.3513e-01,\n",
      "          1.5969e-01,  7.6754e-02,  1.5865e-01, -3.5868e-02, -4.8863e-02,\n",
      "          2.4992e-01,  6.0635e-02,  6.3158e-02,  1.5905e-02,  2.4044e-02,\n",
      "         -1.1957e-01,  1.3696e-01, -8.9048e-02, -1.1089e-01,  4.7672e-02],\n",
      "        [ 9.2829e-03, -7.9966e-02,  1.2839e-03, -1.4355e-01,  1.0766e-01,\n",
      "          3.7560e-01, -5.9204e-02, -1.5383e-01,  1.0104e-01,  6.5150e-02,\n",
      "         -1.2485e-01,  2.4607e-01, -1.3157e-01, -7.4311e-03,  7.4351e-02,\n",
      "         -2.8061e-02, -2.9226e-01,  2.4811e-01,  1.2223e-02, -1.5654e-01],\n",
      "        [-1.7897e-01, -9.4300e-03, -1.5529e-01, -1.7001e-01, -2.0876e-01,\n",
      "          1.4248e-01, -1.6913e-01,  3.0932e-01,  1.0065e-01, -1.1079e-01,\n",
      "          1.1356e-02,  1.6663e-01,  1.9260e-02,  2.5313e-01, -2.1714e-01,\n",
      "          1.7679e-01,  1.9160e-01,  7.0997e-02, -2.6533e-01, -2.7249e-01],\n",
      "        [-9.9904e-02, -1.0899e-01,  1.3226e-01, -1.9044e-01, -1.6486e-01,\n",
      "          3.4666e-01, -9.0987e-02, -7.1825e-02,  6.2680e-02, -1.3272e-02,\n",
      "         -5.2864e-02,  1.5505e-02, -1.0314e-01, -1.7456e-01,  5.1510e-02,\n",
      "         -1.1005e-01,  9.2902e-02, -5.2801e-02, -3.0353e-01, -1.8741e-01],\n",
      "        [-6.5689e-02, -3.6910e-01,  1.4269e-01,  1.4091e-01, -1.5962e-01,\n",
      "          1.3072e-01, -1.6770e-01, -1.6659e-01, -2.5525e-01,  6.4349e-02,\n",
      "          1.1396e-02,  2.1148e-01, -1.5048e-01,  8.0961e-03,  5.8617e-02,\n",
      "          2.0976e-02,  5.3109e-02, -1.0906e-01, -1.9300e-01, -1.6513e-01],\n",
      "        [ 3.2036e-02, -2.3048e-01, -1.3664e-01,  1.6439e-01,  4.4612e-02,\n",
      "          2.1693e-01, -7.7789e-02, -6.2549e-02,  5.6359e-03,  2.0480e-01,\n",
      "         -1.0896e-01,  5.4437e-02,  1.7030e-01, -1.5467e-01, -1.0799e-01,\n",
      "          2.0022e-01,  1.4405e-02,  1.1403e-01, -3.3633e-01,  2.0792e-01],\n",
      "        [-3.1029e-02,  2.4078e-01, -4.3186e-02, -1.3122e-01, -2.0785e-01,\n",
      "         -2.9104e-01,  1.8933e-01, -1.8791e-01,  4.3841e-02,  2.1561e-01,\n",
      "          7.1275e-02, -1.7805e-01, -1.7401e-01, -2.2598e-01,  2.5045e-02,\n",
      "          2.1225e-01,  9.8096e-02,  5.2560e-02,  9.8681e-02,  6.8729e-02],\n",
      "        [ 1.4269e-01,  1.8298e-01, -9.2980e-02, -1.9002e-01,  5.5675e-05,\n",
      "         -2.1921e-01,  1.9354e-01, -1.0107e-01, -2.5850e-01,  1.9835e-01,\n",
      "         -1.6373e-01, -1.6537e-01,  2.0523e-02, -1.7333e-01,  1.5398e-01,\n",
      "          2.3519e-01, -1.8535e-01,  6.9273e-02,  2.0182e-01, -1.5989e-01],\n",
      "        [-1.8696e-01,  3.5817e-02,  8.5749e-02, -8.4586e-02, -4.1375e-02,\n",
      "         -3.6776e-01,  1.3714e-01,  1.4027e-01,  1.2471e-01,  1.2716e-01,\n",
      "          5.3534e-02, -2.5301e-01, -1.0839e-01,  9.9885e-02,  9.2037e-02,\n",
      "         -1.3863e-01, -1.5966e-01,  2.5967e-02,  3.8875e-01, -1.1732e-02],\n",
      "        [-1.5873e-01, -2.6171e-01,  2.5964e-02, -2.4454e-01,  6.8734e-02,\n",
      "         -5.7240e-02,  2.7904e-02, -1.3480e-01, -2.1076e-01, -1.7744e-01,\n",
      "         -1.2839e-01,  2.0899e-01, -2.5260e-01,  2.4553e-02, -1.6588e-01,\n",
      "         -1.4983e-02,  1.8009e-01, -3.6140e-02,  8.8361e-02, -1.2303e-01],\n",
      "        [ 4.2221e-02, -6.6206e-03,  1.9216e-01, -7.5112e-02, -2.4018e-01,\n",
      "          1.3487e-01, -5.4495e-02, -2.6393e-02,  7.3476e-02,  1.4967e-01,\n",
      "         -1.4408e-01, -4.1630e-02,  1.8283e-01,  2.8731e-02,  7.0624e-02,\n",
      "          2.0868e-01,  7.4277e-02, -1.1846e-01, -3.4046e-01, -2.5795e-02],\n",
      "        [ 1.0718e-01,  5.3115e-02,  2.3685e-02,  8.7073e-03, -5.2258e-02,\n",
      "         -2.4281e-01,  2.4700e-01, -8.6247e-02, -2.1075e-01, -2.0671e-01,\n",
      "         -3.0906e-02, -1.6441e-01,  9.5073e-02,  3.0866e-01,  1.6831e-01,\n",
      "          3.3552e-02, -8.9362e-02,  1.9753e-01,  1.1037e-01, -1.7760e-01],\n",
      "        [ 6.3536e-02, -2.6139e-01,  9.6064e-02,  4.0419e-02, -2.2301e-02,\n",
      "          1.8863e-01,  6.1804e-02, -2.2527e-02, -1.4990e-02,  9.7066e-02,\n",
      "          7.8876e-02,  1.8505e-01, -2.3475e-01,  1.1499e-01, -1.1748e-01,\n",
      "         -1.0215e-01, -4.5505e-02, -1.2878e-01, -1.8518e-01, -1.0730e-01],\n",
      "        [-1.4822e-01, -3.0614e-01,  1.2428e-01,  7.7373e-02,  5.9693e-02,\n",
      "          2.4480e-01, -4.7073e-02, -3.9897e-02,  2.6229e-02,  4.2038e-03,\n",
      "          1.5430e-01, -7.1923e-02,  1.7512e-02,  3.0916e-02,  4.2794e-03,\n",
      "         -2.0355e-01, -1.1803e-01,  9.6293e-02, -7.7639e-02,  4.6510e-02],\n",
      "        [ 3.1323e-04,  5.9421e-02, -2.1583e-01, -4.4175e-02, -3.2161e-02,\n",
      "         -4.1851e-01, -1.1068e-01,  1.2583e-01, -1.5530e-01,  1.0251e-01,\n",
      "         -1.3912e-01, -1.1399e-01, -3.3746e-02, -1.4911e-01,  8.6357e-02,\n",
      "         -1.7358e-01, -4.8496e-02, -1.5836e-01,  3.4899e-01, -1.8075e-01],\n",
      "        [-2.7307e-01,  2.4494e-01, -2.8002e-01, -1.2065e-01,  2.2055e-01,\n",
      "         -5.9147e-02, -1.1416e-01, -2.0406e-01, -2.0193e-01,  1.7572e-02,\n",
      "         -2.1005e-01,  1.0628e-01,  1.9544e-01,  1.4614e-01, -9.6238e-02,\n",
      "         -1.8230e-01, -1.3597e-01,  4.1134e-02,  8.8737e-02, -1.2857e-01],\n",
      "        [-1.2654e-03,  1.1685e-02,  7.9099e-02, -1.0035e-01, -7.1775e-02,\n",
      "         -4.4307e-01, -1.2616e-01,  1.6242e-02, -1.6350e-02, -1.5674e-02,\n",
      "          1.1910e-01,  7.5614e-02, -1.8145e-01, -2.1120e-01,  1.9270e-01,\n",
      "          1.6703e-01,  9.3793e-02,  1.2958e-01,  3.0025e-02, -8.9176e-02],\n",
      "        [ 1.4955e-01, -3.9555e-03, -1.1072e-01, -2.1275e-01,  5.4858e-02,\n",
      "          1.0578e-01,  2.3309e-01, -9.9108e-02,  5.5853e-02,  1.6670e-01,\n",
      "         -1.7333e-01, -8.5706e-03,  1.1257e-01, -2.0126e-01,  5.4423e-02,\n",
      "         -1.4778e-01, -1.7832e-02,  5.4437e-02, -1.3897e-01,  4.1684e-03],\n",
      "        [-1.1712e-01,  1.2409e-01, -2.4562e-01, -8.6472e-02,  1.3141e-01,\n",
      "         -9.1636e-02, -1.7764e-01,  1.1471e-02,  1.6879e-01, -2.0599e-01,\n",
      "         -7.3754e-02,  1.4928e-02, -5.8843e-02, -1.6058e-02,  2.7821e-02,\n",
      "          1.6752e-01,  1.2293e-01,  2.7929e-02,  2.8175e-01, -2.4997e-02],\n",
      "        [ 2.1818e-01, -1.7416e-01, -3.2257e-02, -2.7063e-01,  8.5614e-03,\n",
      "         -8.1063e-02,  2.7104e-02,  4.0623e-02, -1.9520e-01,  8.2742e-02,\n",
      "          5.9837e-02,  2.4878e-01,  2.6166e-02, -1.1228e-01,  7.1890e-02,\n",
      "          2.4309e-01, -1.8241e-01,  4.8673e-02, -3.4558e-01, -1.6514e-02],\n",
      "        [ 2.4118e-01, -1.2948e-01, -4.2862e-03, -9.2176e-02,  1.7583e-01,\n",
      "          3.8741e-01,  1.6125e-01,  9.0159e-02,  6.6148e-02, -3.3050e-02,\n",
      "          1.1155e-01,  1.9593e-03, -2.1685e-01,  1.6246e-01,  5.7967e-02,\n",
      "          1.6198e-02,  4.8673e-02, -1.8134e-02, -1.1362e-01,  1.1030e-03],\n",
      "        [ 2.5297e-01,  2.2028e-01, -2.2110e-01, -1.5163e-01, -1.0448e-01,\n",
      "         -1.0378e-01, -1.0122e-01, -9.2287e-02, -5.5052e-02, -7.2448e-02,\n",
      "         -9.1862e-03, -2.1202e-01,  7.8917e-02, -1.8500e-01,  2.5526e-01,\n",
      "          1.7981e-01, -7.8661e-02, -1.5519e-01,  3.0187e-01, -2.7187e-03],\n",
      "        [ 1.1066e-02,  7.5006e-03, -5.6439e-02,  1.7479e-02,  1.5428e-01,\n",
      "          3.0715e-01, -1.9572e-02, -1.3010e-01, -6.8584e-02, -1.2277e-01,\n",
      "         -1.0115e-01,  7.5998e-03, -2.0820e-01,  1.3518e-01, -1.7489e-01,\n",
      "          2.2519e-01, -2.7465e-01, -2.0594e-01, -2.2192e-01,  9.3762e-02],\n",
      "        [ 2.4640e-01, -3.4717e-01,  2.7180e-01,  2.1493e-01,  8.3962e-03,\n",
      "          1.9849e-01, -1.5119e-01,  1.2694e-01,  1.5422e-01,  1.3960e-01,\n",
      "          2.7794e-02, -1.7249e-01,  2.2107e-01, -2.7900e-01,  2.5508e-01,\n",
      "         -9.0683e-02, -5.0828e-02, -1.6039e-01,  2.4064e-02,  8.1847e-03],\n",
      "        [ 5.2239e-03, -2.6189e-01, -1.2419e-02,  1.8460e-01,  3.3335e-02,\n",
      "          1.3895e-02, -1.9790e-01,  2.4490e-01, -1.6107e-01, -4.7742e-03,\n",
      "          2.7332e-01,  1.1921e-01,  1.0857e-01,  3.7667e-02, -2.8438e-01,\n",
      "         -2.5324e-02,  2.5525e-01,  4.7847e-02, -1.4529e-01, -9.2915e-02],\n",
      "        [-4.3305e-02, -3.0394e-01,  1.0321e-01,  2.0053e-02,  1.5389e-02,\n",
      "          2.9628e-01, -1.1271e-01, -1.1209e-01, -1.2755e-01,  6.1842e-02,\n",
      "          2.4323e-01, -6.6273e-02, -8.3843e-02, -1.2316e-01, -2.4642e-02,\n",
      "         -1.7348e-01, -9.6176e-02,  3.7177e-02,  5.3074e-04,  6.8764e-02],\n",
      "        [ 4.0647e-02,  3.6172e-03, -8.4584e-03,  1.6251e-01,  1.0026e-01,\n",
      "         -3.5733e-01, -9.7432e-02, -7.8892e-03, -8.7940e-02, -2.4354e-02,\n",
      "         -5.5534e-02,  3.3603e-02,  2.3859e-03, -5.1940e-02,  2.9016e-01,\n",
      "         -2.6234e-02, -4.2153e-02, -3.5842e-02,  2.3057e-01, -1.5412e-01],\n",
      "        [-3.4946e-02,  1.2157e-01,  1.9099e-01,  1.8703e-01, -1.9434e-02,\n",
      "         -7.1675e-02, -1.1037e-01,  8.5998e-02,  2.2202e-01, -1.6076e-01,\n",
      "          2.1913e-02,  1.8515e-01, -1.8591e-01,  8.2552e-02,  1.2062e-01,\n",
      "         -1.5897e-01,  8.0007e-02,  2.2522e-01, -7.8263e-02,  8.8501e-02],\n",
      "        [ 5.8010e-02,  2.3861e-01, -3.1154e-02,  6.5405e-02, -3.9262e-02,\n",
      "         -3.1800e-01, -3.7757e-02, -1.5578e-01,  9.4163e-02,  3.3204e-02,\n",
      "         -7.4384e-03, -2.1664e-01, -3.9799e-02, -1.1092e-01,  2.4370e-01,\n",
      "         -7.2815e-02, -5.1549e-02, -2.0191e-01,  3.4667e-01, -4.2741e-02],\n",
      "        [-1.9305e-01, -1.1641e-02, -1.1505e-01,  1.1204e-01, -1.8437e-01,\n",
      "          2.6366e-01,  2.5058e-01,  2.9583e-01,  1.3911e-02, -5.3867e-02,\n",
      "          1.0372e-01,  1.5234e-01, -1.3987e-01, -1.4718e-01,  1.2675e-01,\n",
      "         -2.2167e-01, -1.5951e-01, -7.9036e-02,  2.0541e-02, -1.7305e-01]])\n",
      "fc1.bias: tensor([ 0.1360,  0.1619,  0.1426, -0.1020,  0.1886,  0.2246, -0.1414,  0.3482,\n",
      "        -0.0103,  0.2609,  0.2338,  0.0442,  0.0693,  0.2360,  0.2679,  0.0097,\n",
      "         0.3499,  0.1932,  0.0868,  0.1980,  0.0123, -0.1511, -0.0086, -0.1226,\n",
      "         0.2633,  0.3181,  0.0674,  0.1851,  0.2268,  0.2778,  0.0303,  0.2681])\n",
      "fc2.weight: tensor([[ 6.3193e-02,  1.2488e-01, -1.5306e-01, -3.3759e-02, -3.3771e-02,\n",
      "         -4.8132e-02, -7.5581e-02,  1.0934e-01,  1.3661e-01,  1.0969e-01,\n",
      "          2.0780e-01,  3.4646e-02,  3.2747e-02, -2.3999e-03,  2.4222e-02,\n",
      "         -7.4657e-02,  2.8059e-02,  1.4653e-01,  1.9422e-01, -1.0497e-01,\n",
      "          1.2309e-01,  1.0330e-01, -1.2698e-01,  2.3795e-01, -2.0526e-01,\n",
      "         -4.0273e-02, -7.3987e-02,  8.1612e-02, -4.2979e-03,  1.9640e-01,\n",
      "          3.6141e-02, -1.3254e-01],\n",
      "        [-6.2620e-03,  1.6265e-01, -1.8676e-01, -6.3839e-03, -1.8146e-02,\n",
      "          1.8231e-02, -6.5431e-02, -7.7833e-02, -9.6757e-02, -1.4392e-01,\n",
      "         -5.0587e-02,  1.5134e-02,  1.0407e-01,  1.8438e-01,  4.5539e-02,\n",
      "         -6.9036e-02, -9.6569e-02,  1.6258e-01,  1.7940e-02,  4.6048e-02,\n",
      "          1.1232e-01, -1.8817e-01, -1.2621e-01, -1.2010e-01, -1.0024e-01,\n",
      "         -1.3782e-02,  1.0531e-01,  1.3804e-01, -9.2845e-02, -7.1419e-02,\n",
      "          1.1865e-01,  7.0177e-02],\n",
      "        [ 1.3904e-01,  3.6029e-02,  1.4660e-03,  1.8970e-01, -3.3939e-04,\n",
      "          1.6206e-01,  2.4049e-01,  2.9893e-01, -1.9299e-01, -7.8177e-02,\n",
      "         -1.9792e-01,  1.3633e-01,  1.9472e-01,  1.6077e-02,  1.4200e-01,\n",
      "          8.1154e-02,  3.7252e-02,  4.4835e-02, -4.9018e-02,  1.5301e-01,\n",
      "         -1.4188e-01,  1.1622e-01,  2.2813e-01, -1.3579e-01,  2.6960e-01,\n",
      "          1.3882e-01,  1.0939e-01,  4.5094e-02, -2.8327e-01, -5.1732e-02,\n",
      "         -2.9139e-01,  2.4476e-01],\n",
      "        [ 8.5417e-02, -8.4039e-02,  3.0019e-01,  1.5160e-01,  1.7480e-01,\n",
      "          1.6211e-01, -9.9939e-03,  3.0764e-01, -1.2163e-01,  7.9731e-02,\n",
      "         -1.2618e-01,  1.0564e-01,  1.5052e-01, -1.0372e-01,  2.6140e-01,\n",
      "          2.6841e-01, -9.0063e-02,  1.1415e-01, -1.1152e-01,  1.3181e-01,\n",
      "         -1.5780e-01,  5.6681e-02,  2.7325e-01, -1.1200e-01,  1.1455e-01,\n",
      "          2.4896e-01,  4.9075e-02,  3.1494e-01, -1.5519e-01,  2.1638e-01,\n",
      "         -2.4477e-01,  4.5463e-03],\n",
      "        [ 1.9193e-01,  1.2326e-02, -2.4630e-01, -1.7801e-01,  1.3712e-03,\n",
      "         -2.0502e-01, -8.2807e-02, -1.6859e-01,  1.6023e-01,  2.8889e-01,\n",
      "          4.8751e-02, -9.1255e-02,  3.7669e-02,  4.9134e-02,  4.3782e-02,\n",
      "          7.5136e-02,  1.4962e-01, -6.3045e-02,  2.2908e-01, -3.8539e-03,\n",
      "          9.7920e-02,  4.8875e-02, -1.0285e-01,  2.3129e-01, -5.5465e-02,\n",
      "         -1.0381e-01, -1.1945e-02, -6.1640e-02,  1.2211e-01,  1.9343e-01,\n",
      "          1.0270e-01,  1.9148e-01],\n",
      "        [ 3.0550e-02, -3.2072e-02,  1.0147e-02,  1.6911e-01, -6.0004e-03,\n",
      "          5.0441e-02,  9.2571e-02, -3.3464e-02, -1.2150e-01,  3.6110e-02,\n",
      "         -9.8640e-02, -1.0704e-01,  1.1988e-01,  5.6025e-02,  1.1637e-01,\n",
      "         -8.2745e-02,  8.9418e-02, -1.3978e-02,  7.9123e-02,  1.0139e-01,\n",
      "          3.6742e-03,  1.4606e-01,  6.4940e-02, -1.3674e-01,  2.7196e-01,\n",
      "          1.2482e-01,  1.7350e-01, -3.0273e-02, -1.8774e-01, -3.1371e-02,\n",
      "         -1.0562e-01,  3.4813e-02],\n",
      "        [ 2.4111e-02,  1.0642e-01,  1.8019e-02,  3.8904e-02, -2.0833e-02,\n",
      "          2.5736e-01,  2.1655e-01,  2.1481e-01, -2.1051e-02, -1.0743e-01,\n",
      "         -1.5453e-01,  1.2786e-01,  9.4985e-02,  5.2302e-02,  1.7465e-01,\n",
      "          2.8736e-01, -1.7778e-01,  1.2589e-01, -6.6119e-02,  6.5555e-02,\n",
      "         -1.0410e-01,  1.6692e-01,  2.1161e-01,  1.7764e-02,  2.3012e-01,\n",
      "          2.3648e-01,  8.9883e-03,  1.0195e-01, -1.2626e-01,  1.0271e-01,\n",
      "         -1.7383e-01,  1.1323e-01],\n",
      "        [ 1.4302e-02,  2.9454e-01, -1.8991e-01, -4.3137e-02,  1.3535e-01,\n",
      "          6.0091e-02, -7.5592e-02, -4.2920e-02,  1.1350e-01,  2.1355e-01,\n",
      "          3.6918e-01,  5.2399e-02, -1.6406e-01,  2.9411e-01, -2.0466e-01,\n",
      "         -1.9351e-01,  1.6842e-01,  1.5538e-01,  3.0130e-01, -4.7395e-03,\n",
      "          2.6615e-01,  2.6421e-02, -7.0774e-03, -3.5927e-02, -1.2125e-01,\n",
      "          1.7976e-01, -1.3396e-01, -2.0158e-01,  1.7510e-01,  6.7052e-02,\n",
      "          1.6612e-01,  4.4898e-02],\n",
      "        [-3.0048e-02, -5.5876e-02, -1.0946e-03,  4.7269e-02,  1.7635e-01,\n",
      "          3.1039e-01,  1.2047e-01,  2.7189e-01, -7.1548e-02,  2.0016e-02,\n",
      "         -2.3810e-01,  1.4158e-01,  3.4658e-02,  6.2654e-02,  1.5282e-01,\n",
      "          2.6539e-02, -1.2315e-01, -1.0106e-01, -1.8582e-01, -5.6484e-02,\n",
      "          4.0196e-02,  1.7420e-01,  8.3366e-02,  1.2607e-02,  2.8979e-01,\n",
      "          1.1279e-01,  2.3505e-01,  2.3427e-01, -6.9571e-02, -1.6482e-02,\n",
      "         -2.8394e-02,  2.4850e-01],\n",
      "        [ 9.5963e-02, -1.5307e-01,  1.0664e-01,  3.7507e-01,  1.7303e-01,\n",
      "          1.0408e-01,  1.7840e-01,  4.1661e-02, -2.1713e-01,  1.1230e-01,\n",
      "         -1.5375e-01, -9.0612e-02,  1.8166e-01, -2.1300e-01,  2.0928e-01,\n",
      "          1.8966e-01, -2.2803e-01,  1.0878e-01,  1.3639e-02,  1.5922e-01,\n",
      "          5.5627e-02,  7.3686e-03,  9.1245e-02,  5.9094e-02,  2.6921e-01,\n",
      "          1.0926e-01,  2.2895e-01,  1.8454e-01, -4.2738e-02,  7.5071e-02,\n",
      "         -1.5500e-01,  2.7802e-01],\n",
      "        [-1.3303e-01,  1.5100e-02, -1.9518e-01,  1.2410e-01, -5.1342e-02,\n",
      "         -9.3497e-02, -1.1638e-01,  1.1571e-01, -1.5803e-01,  7.9907e-02,\n",
      "          4.3063e-02,  8.2233e-02, -5.4905e-02, -3.7736e-02, -1.3440e-01,\n",
      "          1.4926e-01, -9.8992e-02,  6.7258e-02, -1.3192e-01,  1.1847e-01,\n",
      "          2.8902e-02,  9.3564e-02,  5.0997e-03,  3.7630e-02, -6.5820e-02,\n",
      "         -1.2079e-02, -1.1484e-01, -7.7706e-02,  7.0942e-02, -7.4519e-02,\n",
      "          6.8516e-02,  6.3747e-02],\n",
      "        [ 2.3201e-01,  1.9900e-01, -2.2373e-02, -1.1061e-01,  2.1944e-02,\n",
      "          1.6322e-02, -1.6465e-02, -2.7862e-02,  4.6029e-02,  2.5771e-01,\n",
      "          3.7643e-01,  3.9979e-02, -2.2053e-01,  6.0435e-02, -1.1825e-01,\n",
      "         -3.1434e-02,  2.6047e-01,  2.1495e-01,  1.6720e-01,  2.8457e-02,\n",
      "          3.1150e-01,  9.0706e-02,  4.1595e-02,  1.8796e-01, -5.5011e-02,\n",
      "         -1.3773e-02,  1.1709e-01, -1.3292e-01,  2.4889e-01, -6.0853e-02,\n",
      "          1.7325e-01, -8.2557e-02],\n",
      "        [ 1.4032e-01,  8.9266e-02, -2.2613e-01, -2.9133e-01, -5.5035e-02,\n",
      "         -5.9872e-02, -1.7639e-02, -9.2065e-02,  1.9857e-01,  9.8303e-02,\n",
      "          8.7146e-02, -7.8839e-02, -1.2282e-01,  2.3954e-01, -4.9739e-02,\n",
      "          5.8197e-02,  2.6975e-01,  1.5071e-01,  7.4353e-02,  1.2176e-01,\n",
      "         -4.2532e-02, -8.4409e-03, -1.6795e-01,  1.6806e-01,  1.6599e-02,\n",
      "          7.8415e-02,  2.5794e-02, -2.2922e-01,  1.4345e-01,  1.4649e-01,\n",
      "          2.3745e-01,  1.3578e-01],\n",
      "        [-2.8813e-02, -8.3068e-02,  1.8962e-01,  9.7734e-02,  1.9624e-01,\n",
      "          2.3263e-01,  1.1443e-01,  1.8284e-01, -1.0024e-01, -1.2667e-01,\n",
      "          1.7562e-03,  1.8695e-02,  2.9670e-01, -8.3924e-02, -1.6874e-02,\n",
      "         -6.5099e-02, -1.4595e-01,  4.3870e-02, -1.7115e-01,  1.9087e-01,\n",
      "         -3.9629e-02,  8.1585e-02,  2.1195e-01, -1.6481e-01,  2.4698e-01,\n",
      "          7.5715e-02,  1.7428e-01,  1.8851e-01, -1.8374e-01,  1.1390e-01,\n",
      "          7.9328e-02,  1.5547e-01],\n",
      "        [-4.5917e-02,  1.2727e-01,  1.2058e-01,  3.2944e-01,  2.0741e-01,\n",
      "          1.7588e-01,  3.1075e-01,  2.0077e-01, -1.9784e-02,  8.9968e-03,\n",
      "         -7.1165e-02,  2.6205e-02,  1.2147e-01, -9.8244e-02,  2.6804e-01,\n",
      "          9.5886e-02, -2.7677e-01,  1.6469e-01, -6.9514e-03, -3.4542e-02,\n",
      "         -1.9488e-01, -7.7740e-02,  2.0615e-01,  6.5366e-02,  4.1694e-02,\n",
      "          9.4954e-03,  9.1815e-02,  1.5209e-01, -8.0007e-02,  8.0145e-02,\n",
      "         -2.8417e-02,  1.3271e-01],\n",
      "        [ 2.2305e-01,  1.3269e-01, -1.8936e-01, -2.6663e-01,  1.0559e-01,\n",
      "         -2.1804e-01, -3.0198e-02, -7.3681e-02,  2.1822e-01,  1.0691e-01,\n",
      "          6.9616e-02,  1.6084e-01, -9.4008e-02,  2.0571e-01, -6.6270e-02,\n",
      "          6.5412e-02,  2.7428e-02, -1.6862e-02,  1.7505e-01, -9.7761e-02,\n",
      "          1.1347e-01, -1.3526e-01, -6.7581e-02,  1.4445e-01,  5.3964e-02,\n",
      "          5.0118e-02, -1.9872e-01, -1.1589e-01,  1.7331e-01,  1.8191e-01,\n",
      "          2.6638e-01,  9.6462e-02]])\n",
      "fc2.bias: tensor([ 0.0617, -0.1362,  0.1392,  0.0415,  0.0527,  0.0268,  0.0170,  0.1689,\n",
      "         0.0590,  0.0877, -0.1955,  0.0102,  0.2603,  0.1291,  0.0143,  0.0274])\n",
      "fc3.weight: tensor([[-0.2663, -0.1359,  0.2429,  0.2855, -0.1913,  0.3467,  0.1556, -0.3248,\n",
      "          0.4252,  0.1841,  0.1594, -0.2644, -0.4192,  0.1403,  0.1747, -0.1408]])\n",
      "fc3.bias: tensor([-0.1201])\n"
     ]
    }
   ],
   "source": [
    "for param_tensor in state_dict:\n",
    "    print(f\"{param_tensor}: {state_dict[param_tensor]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da15cf",
   "metadata": {},
   "source": [
    "# Pytorch Approach for Binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a96a5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Generate a sample binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Define a simple neural network\n",
    "class TorchBinaryClassifier(nn.Module):  # Changed model name to unique\n",
    "    def __init__(self, input_dim):\n",
    "        super(TorchBinaryClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward pass through the network\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "torch_binary_classifier = TorchBinaryClassifier(X_train.shape[1])\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()  # Binary cross-entropy loss\n",
    "optimizer = optim.Adam(torch_binary_classifier.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "for epoch in range(epochs):\n",
    "    permutation = torch.randperm(X_train_tensor.size()[0])\n",
    "    for i in range(0, X_train_tensor.size()[0], batch_size):\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = X_train_tensor[indices], y_train_tensor[indices]\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = torch_binary_classifier(batch_x)  # Forward pass\n",
    "        loss = criterion(outputs, batch_y)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "# Evaluation\n",
    "with torch.no_grad():\n",
    "    outputs = torch_binary_classifier(X_test_tensor)  # Forward pass on test set\n",
    "    predicted = (outputs > 0.5).float()  # Threshold predictions\n",
    "    accuracy = (predicted.eq(y_test_tensor).sum().item()) / y_test_tensor.size(0)\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ada729",
   "metadata": {},
   "source": [
    "# Custom Bespoke Approach for Binaary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7089dabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6929\n",
      "Epoch 2/10, Loss: 0.6933\n",
      "Epoch 3/10, Loss: 0.6928\n",
      "Epoch 4/10, Loss: 0.6952\n",
      "Epoch 5/10, Loss: 0.6954\n",
      "Epoch 6/10, Loss: 0.6956\n",
      "Epoch 7/10, Loss: 0.6924\n",
      "Epoch 8/10, Loss: 0.6967\n",
      "Epoch 9/10, Loss: 0.6954\n",
      "Epoch 10/10, Loss: 0.6944\n",
      "Test Accuracy: 0.47\n"
     ]
    }
   ],
   "source": [
    "# Simple neural network from scratch (no frameworks) for binary classification\n",
    "\n",
    "# Use X_train, y_train, X_test, y_test from previous cells\n",
    "\n",
    "# Sigmoid activation function and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "# Initialize parameters\n",
    "np.random.seed(42)\n",
    "input_dim = X_train.shape[1]\n",
    "hidden1_dim = 32\n",
    "hidden2_dim = 16\n",
    "output_dim = 1\n",
    "\n",
    "W1 = np.random.randn(input_dim, hidden1_dim) * 0.01\n",
    "b1 = np.zeros((1, hidden1_dim))\n",
    "W2 = np.random.randn(hidden1_dim, hidden2_dim) * 0.01\n",
    "b2 = np.zeros((1, hidden2_dim))\n",
    "W3 = np.random.randn(hidden2_dim, output_dim) * 0.01\n",
    "b3 = np.zeros((1, output_dim))\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    permutation = np.random.permutation(X_train.shape[0])\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        idx = permutation[i:i+batch_size]\n",
    "        Xb = X_train[idx]\n",
    "        yb = y_train[idx].reshape(-1, 1)\n",
    "        \n",
    "        # Forward pass\n",
    "        z1 = Xb @ W1 + b1\n",
    "        a1 = sigmoid(z1)\n",
    "        z2 = a1 @ W2 + b2\n",
    "        a2 = sigmoid(z2)\n",
    "        z3 = a2 @ W3 + b3\n",
    "        a3 = sigmoid(z3)\n",
    "        \n",
    "        # Compute loss (binary cross-entropy)\n",
    "        loss = -np.mean(yb * np.log(a3 + 1e-8) + (1 - yb) * np.log(1 - a3 + 1e-8))\n",
    "        \n",
    "        # Backward pass\n",
    "        dz3 = a3 - yb\n",
    "        dW3 = a2.T @ dz3 / batch_size\n",
    "        db3 = np.sum(dz3, axis=0, keepdims=True) / batch_size\n",
    "        \n",
    "        da2 = dz3 @ W3.T\n",
    "        dz2 = da2 * sigmoid_deriv(z2)\n",
    "        dW2 = a1.T @ dz2 / batch_size\n",
    "        db2 = np.sum(dz2, axis=0, keepdims=True) / batch_size\n",
    "        \n",
    "        da1 = dz2 @ W2.T\n",
    "        dz1 = da1 * sigmoid_deriv(z1)\n",
    "        dW1 = Xb.T @ dz1 / batch_size\n",
    "        db1 = np.sum(dz1, axis=0, keepdims=True) / batch_size\n",
    "        \n",
    "        # Update weights\n",
    "        W3 -= lr * dW3\n",
    "        b3 -= lr * db3\n",
    "        W2 -= lr * dW2\n",
    "        b2 -= lr * db2\n",
    "        W1 -= lr * dW1\n",
    "        b1 -= lr * db1\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "z1 = X_test @ W1 + b1\n",
    "a1 = sigmoid(z1)\n",
    "z2 = a1 @ W2 + b2\n",
    "a2 = sigmoid(z2)\n",
    "z3 = a2 @ W3 + b3\n",
    "a3 = sigmoid(z3)\n",
    "preds = (a3 > 0.5).astype(int)\n",
    "accuracy = np.mean(preds.flatten() == y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a70b89",
   "metadata": {},
   "source": [
    "\n",
    "### Assignment 1: Model Comparison\n",
    "**Task:**  \n",
    "Compare the test accuracy of the three binary classification approaches (Keras/TensorFlow, PyTorch, and NumPy-from-scratch).  \n",
    "**Instructions:**  \n",
    "- Collect the test accuracy from each approach.\n",
    "- Present the results in a table.\n",
    "- Briefly discuss which approach performed best and why you think that is.\n",
    "\n",
    "---\n",
    "\n",
    "### Assignment 2: Model Architecture Exploration\n",
    "**Task:**  \n",
    "Modify the neural network architectures in both the PyTorch and NumPy-from-scratch implementations.  \n",
    "**Instructions:**  \n",
    "- Change the number of hidden layers and/or the number of neurons per layer.\n",
    "- Retrain the models and report the new test accuracies.\n",
    "- Discuss how the changes affected performance.\n",
    "\n",
    "---\n",
    "\n",
    "### Assignment 3: Model Persistence and Inference\n",
    "**Task:**  \n",
    "Work with the saved PyTorch model.  \n",
    "**Instructions:**  \n",
    "- Load the saved model weights into a new model instance.\n",
    "- Use the loaded model to make predictions on new data (e.g., `sample_inputs`).\n",
    "- Compare the predictions to the true labels.\n",
    "\n",
    "---\n",
    "\n",
    "### Assignment 4: Feature Importance Investigation\n",
    "**Task:**  \n",
    "Investigate which features are most important for the classification task.  \n",
    "**Instructions:**  \n",
    "- Use the weights of the first layer in either the PyTorch or NumPy model.\n",
    "- Identify which input features have the largest absolute weights.\n",
    "- Discuss what this might mean about the data.\n",
    "\n",
    "---\n",
    "\n",
    "### Assignment 5: Custom Evaluation Metric\n",
    "**Task:**  \n",
    "Implement a custom evaluation metric (e.g., precision, recall, F1-score) for the predictions of any model.  \n",
    "**Instructions:**  \n",
    "- Write a function to compute the metric.\n",
    "- Apply it to the predictions and true labels.\n",
    "- Interpret the results.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "module1_dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
