{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment 7: Pre-trained Models for Oil & Gas Equipment Classification\n",
        "\n",
        "**Course:** Introduction to Deep Learning | **Module:** Transfer Learning\n",
        "\n",
        "---\n",
        "\n",
        "## Objective\n",
        "\n",
        "Explore and implement pre-trained deep learning models for oil & gas equipment image classification using transfer learning techniques, comparing different architectures and fine-tuning strategies.\n",
        "\n",
        "## Learning Outcomes\n",
        "\n",
        "By the end of this experiment, you will:\n",
        "\n",
        "1. Understand transfer learning principles and pre-trained model advantages\n",
        "2. Implement multiple pre-trained architectures (ResNet, EfficientNet, MobileNet, ViT)\n",
        "3. Apply different fine-tuning strategies for domain adaptation\n",
        "4. Compare model performance, efficiency, and deployment considerations\n",
        "5. Optimize models for edge deployment and production environments\n",
        "\n",
        "## Background & Theory\n",
        "\n",
        "**Transfer Learning** leverages knowledge gained from pre-trained models on large datasets (like ImageNet) and adapts them to specific domains. This approach significantly reduces training time and data requirements while achieving superior performance.\n",
        "\n",
        "**Key Concepts:**\n",
        "\n",
        "- **Pre-trained Models:** Networks trained on large-scale datasets with learned feature representations\n",
        "- **Feature Extraction:** Using pre-trained features with frozen weights\n",
        "- **Fine-tuning:** Adapting pre-trained weights to new domain with lower learning rates\n",
        "- **Domain Adaptation:** Adjusting models from general to specific application domains\n",
        "- **Model Efficiency:** Balancing accuracy with computational and memory requirements\n",
        "\n",
        "**Mathematical Foundation:**\n",
        "\n",
        "- Transfer learning: f_target(x) = g(f_pretrained(x)) where g is domain-specific head\n",
        "- Fine-tuning loss: L = L_task + λL_regularization\n",
        "- Learning rate scheduling: lr_fine = α × lr_pretrained where α << 1\n",
        "- Feature similarity: sim(f_source, f_target) = cos(f_source, f_target)\n",
        "\n",
        "**Model Architectures:**\n",
        "\n",
        "- **ResNet:** Deep residual networks with skip connections\n",
        "- **EfficientNet:** Compound scaling for optimal accuracy-efficiency trade-off\n",
        "- **MobileNet:** Lightweight architecture for mobile deployment\n",
        "- **Vision Transformer:** Attention-based architecture for image understanding\n",
        "\n",
        "**Applications in Oil & Gas:**\n",
        "\n",
        "- Automated equipment inspection and condition monitoring\n",
        "- Safety compliance verification through image analysis\n",
        "- Predictive maintenance based on visual equipment assessment\n",
        "- Remote monitoring of offshore and onshore facilities\n",
        "- Quality control in manufacturing and installation processes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup & Dependencies\n",
        "\n",
        "**What to Expect:** This section establishes the Python environment for transfer learning with pre-trained models. We'll install PyTorch, torchvision for pre-trained models, and timm library for state-of-the-art architectures like EfficientNet and Vision Transformers.\n",
        "\n",
        "**Process Overview:**\n",
        "\n",
        "1. **Package Installation:** Install PyTorch ecosystem (torch, torchvision), timm for advanced models, and image processing libraries\n",
        "2. **Model Library Setup:** Configure access to pre-trained models from ImageNet and other large-scale datasets\n",
        "3. **Environment Configuration:** Set up device detection (CPU/GPU) and random seeds for reproducible transfer learning\n",
        "4. **Image Processing Tools:** Configure PIL, transforms, and data loading utilities for image classification\n",
        "5. **Evaluation Framework:** Set up metrics and visualization tools for comparing different architectures\n",
        "\n",
        "**Expected Outcome:** A fully configured environment ready for transfer learning experiments with multiple pre-trained architectures (ResNet, EfficientNet, MobileNet, ViT) and comprehensive evaluation tools.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Suni Files\\AI Code Base\\Oil and Gas\\Oil and Gas Pruthvi College Course Material\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ PyTorch version: 2.8.0+cpu\n",
            "✓ Torchvision version: 2.8.0+cpu\n",
            "✓ TIMM version: 1.0.20\n",
            "✓ Device: cpu\n",
            "✓ Data directory: d:\\Suni Files\\AI Code Base\\Oil and Gas\\Oil and Gas Pruthvi College Course Material\\Updated\\Expirements\\Experiment_7_Pretrained_Models\\data\n",
            "✓ All packages installed and configured\n",
            "✓ Random seeds set for reproducible results\n",
            "✓ ArivuAI styling applied\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "import subprocess, sys\n",
        "packages = ['torch', 'torchvision', 'numpy', 'matplotlib', 'pandas', 'scikit-learn', 'Pillow', 'timm']\n",
        "for pkg in packages:\n",
        "    try: \n",
        "        if pkg == 'timm': __import__('timm')\n",
        "        else: __import__(pkg.replace('-', '_').lower())\n",
        "    except ImportError: \n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg])\n",
        "\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import timm  # PyTorch Image Models for additional architectures\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import json, random, time\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Data directory setup\n",
        "DATA_DIR = Path('data')\n",
        "if not DATA_DIR.exists():\n",
        "    DATA_DIR = Path('Expirements/data')\n",
        "if not DATA_DIR.exists():\n",
        "    DATA_DIR = Path('.')\n",
        "    print('Warning: Using current directory for data')\n",
        "\n",
        "# ArivuAI styling\n",
        "plt.style.use('default')\n",
        "colors = {'primary': '#004E89', 'secondary': '#3DA5D9', 'accent': '#F1A208', 'dark': '#4F4F4F'}\n",
        "\n",
        "print(f'✓ PyTorch version: {torch.__version__}')\n",
        "print(f'✓ Torchvision version: {torch.version.__version__ if hasattr(torch.version, \"__version__\") else \"N/A\"}')\n",
        "print(f'✓ TIMM version: {timm.__version__}')\n",
        "print(f'✓ Device: {device}')\n",
        "print(f'✓ Data directory: {DATA_DIR.absolute()}')\n",
        "print('✓ All packages installed and configured')\n",
        "print('✓ Random seeds set for reproducible results')\n",
        "print('✓ ArivuAI styling applied')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pre-trained Model Configuration\n",
        "\n",
        "Load configuration and set up different pre-trained architectures for comparison.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Configuration loaded from JSON\n",
            "✓ Pre-trained model manager initialized\n",
            "✓ Available models: ['resnet50', 'efficientnet_b0', 'mobilenet_v3', 'vit_base']\n",
            "✓ Number of classes: 8\n",
            "✓ Equipment classes: ['Drilling_Rig', 'Pump_Jack', 'Storage_Tank', 'Pipeline_Valve', 'Compressor_Station', 'Flare_Stack', 'Separator_Vessel', 'Control_Panel']\n",
            "\n",
            "Model Comparison:\n",
            "             Model Parameters Input Size ImageNet Accuracy             Key Advantage\n",
            "         ResNet-50      25.6M    224x224            76.15% Deep residual connections\n",
            "   EfficientNet-B0       5.3M    224x224            77.69%          Compound scaling\n",
            "      MobileNet-V3       4.2M    224x224            75.77%        Lightweight design\n",
            "Vision Transformer        86M    224x224            84.53%      Attention mechanisms\n"
          ]
        }
      ],
      "source": [
        "class PretrainedModelManager:\n",
        "    def __init__(self, config_path):\n",
        "        \"\"\"Initialize pre-trained model manager with configuration\"\"\"\n",
        "        try:\n",
        "            with open(config_path, 'r') as f:\n",
        "                self.config = json.load(f)\n",
        "            print('✓ Configuration loaded from JSON')\n",
        "        except FileNotFoundError:\n",
        "            print('Creating default configuration...')\n",
        "            self.config = self._create_default_config()\n",
        "        \n",
        "        self.pretrained_models = self.config['pretrained_models']\n",
        "        self.num_classes = len(self.config['oil_gas_equipment_classes'])\n",
        "        self.class_names = self.config['oil_gas_equipment_classes']\n",
        "    \n",
        "    def _create_default_config(self):\n",
        "        \"\"\"Create default configuration if JSON file not found\"\"\"\n",
        "        return {\n",
        "            'pretrained_models': {\n",
        "                'resnet50': {'architecture': 'ResNet-50', 'parameters': '25.6M'},\n",
        "                'efficientnet_b0': {'architecture': 'EfficientNet-B0', 'parameters': '5.3M'}\n",
        "            },\n",
        "            'oil_gas_equipment_classes': {\n",
        "                '0': 'Drilling_Rig', '1': 'Pump_Jack', '2': 'Storage_Tank', '3': 'Pipeline_Valve'\n",
        "            }\n",
        "        }\n",
        "    \n",
        "    def create_model(self, model_name, strategy='feature_extraction'):\n",
        "        \"\"\"Create and configure pre-trained model for transfer learning\"\"\"\n",
        "        if model_name == 'resnet50':\n",
        "            model = models.resnet50(pretrained=True)\n",
        "            # Replace final layer\n",
        "            model.fc = nn.Linear(model.fc.in_features, self.num_classes)\n",
        "            \n",
        "        elif model_name == 'efficientnet_b0':\n",
        "            model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=self.num_classes)\n",
        "            \n",
        "        elif model_name == 'mobilenet_v3':\n",
        "            model = models.mobilenet_v3_large(pretrained=True)\n",
        "            model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, self.num_classes)\n",
        "            \n",
        "        elif model_name == 'vit_base':\n",
        "            model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=self.num_classes)\n",
        "            \n",
        "        else:\n",
        "            raise ValueError(f\"Unknown model: {model_name}\")\n",
        "        \n",
        "        # Apply transfer learning strategy\n",
        "        if strategy == 'feature_extraction':\n",
        "            # Freeze all layers except classifier\n",
        "            for param in model.parameters():\n",
        "                param.requires_grad = False\n",
        "            \n",
        "            # Unfreeze classifier layers\n",
        "            if hasattr(model, 'fc'):\n",
        "                for param in model.fc.parameters():\n",
        "                    param.requires_grad = True\n",
        "            elif hasattr(model, 'classifier'):\n",
        "                for param in model.classifier.parameters():\n",
        "                    param.requires_grad = True\n",
        "            elif hasattr(model, 'head'):\n",
        "                for param in model.head.parameters():\n",
        "                    param.requires_grad = True\n",
        "        \n",
        "        elif strategy == 'fine_tuning':\n",
        "            # Freeze early layers, unfreeze later layers\n",
        "            total_layers = len(list(model.parameters()))\n",
        "            freeze_layers = int(total_layers * 0.7)  # Freeze 70% of layers\n",
        "            \n",
        "            for i, param in enumerate(model.parameters()):\n",
        "                param.requires_grad = i >= freeze_layers\n",
        "        \n",
        "        # Full fine-tuning keeps all parameters trainable (default)\n",
        "        \n",
        "        return model\n",
        "    \n",
        "    def get_model_info(self, model_name):\n",
        "        \"\"\"Get detailed information about a specific model\"\"\"\n",
        "        if model_name in self.pretrained_models:\n",
        "            return self.pretrained_models[model_name]\n",
        "        return None\n",
        "    \n",
        "    def compare_models(self):\n",
        "        \"\"\"Compare different pre-trained models\"\"\"\n",
        "        comparison_data = []\n",
        "        \n",
        "        for model_name, info in self.pretrained_models.items():\n",
        "            comparison_data.append({\n",
        "                'Model': info['architecture'],\n",
        "                'Parameters': info['parameters'],\n",
        "                'Input Size': f\"{info['input_size'][0]}x{info['input_size'][1]}\",\n",
        "                'ImageNet Accuracy': f\"{info['top1_accuracy']:.2f}%\",\n",
        "                'Key Advantage': info['advantages'][0]\n",
        "            })\n",
        "        \n",
        "        return pd.DataFrame(comparison_data)\n",
        "\n",
        "# Initialize model manager\n",
        "model_manager = PretrainedModelManager(DATA_DIR / 'pretrained_image_config.json')\n",
        "\n",
        "print(f'✓ Pre-trained model manager initialized')\n",
        "print(f'✓ Available models: {list(model_manager.pretrained_models.keys())}')\n",
        "print(f'✓ Number of classes: {model_manager.num_classes}')\n",
        "print(f'✓ Equipment classes: {list(model_manager.class_names.values())}')\n",
        "\n",
        "# Display model comparison\n",
        "print('\\nModel Comparison:')\n",
        "comparison_df = model_manager.compare_models()\n",
        "print(comparison_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Synthetic Dataset Generation\n",
        "\n",
        "Create synthetic oil & gas equipment images for transfer learning experiments.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating synthetic equipment images...\n",
            "✓ Generated 800 synthetic images\n",
            "✓ Dataset created and split:\n",
            "• Training: 560 samples\n",
            "• Validation: 120 samples\n",
            "• Test: 120 samples\n",
            "• Classes: ['Drilling_Rig', 'Pump_Jack', 'Storage_Tank', 'Pipeline_Valve', 'Compressor_Station', 'Flare_Stack', 'Separator_Vessel', 'Control_Panel']\n"
          ]
        }
      ],
      "source": [
        "class SyntheticEquipmentDataset(Dataset):\n",
        "    def __init__(self, model_manager, samples_per_class=100, transform=None):\n",
        "        \"\"\"Create synthetic dataset for oil & gas equipment\"\"\"\n",
        "        self.model_manager = model_manager\n",
        "        self.transform = transform\n",
        "        self.samples_per_class = samples_per_class\n",
        "        self.class_names = model_manager.class_names\n",
        "        self.num_classes = len(self.class_names)\n",
        "        \n",
        "        # Generate synthetic images and labels\n",
        "        print('Generating synthetic equipment images...')\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        \n",
        "        for class_id in range(self.num_classes):\n",
        "            for _ in range(samples_per_class):\n",
        "                img = self._generate_equipment_image(class_id)\n",
        "                self.images.append(img)\n",
        "                self.labels.append(class_id)\n",
        "        \n",
        "        print(f'✓ Generated {len(self.images)} synthetic images')\n",
        "    \n",
        "    def _generate_equipment_image(self, class_id):\n",
        "        \"\"\"Generate synthetic equipment image based on class\"\"\"\n",
        "        # Create base image\n",
        "        img = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "        \n",
        "        # Background (industrial setting)\n",
        "        bg_color = [135, 135, 135] + np.random.randint(-20, 20, 3)\n",
        "        img[:, :] = np.clip(bg_color, 0, 255)\n",
        "        \n",
        "        # Equipment-specific patterns\n",
        "        if class_id == 0:  # Drilling_Rig\n",
        "            # Vertical tower structure\n",
        "            tower_width = 30\n",
        "            center_x = 112\n",
        "            img[20:200, center_x-tower_width//2:center_x+tower_width//2] = [100, 80, 60]\n",
        "            \n",
        "        elif class_id == 1:  # Pump_Jack\n",
        "            # Curved beam structure\n",
        "            center_x, center_y = 80, 112\n",
        "            img[center_y-10:center_y+10, center_x:center_x+80] = [120, 100, 80]\n",
        "            \n",
        "        elif class_id == 2:  # Storage_Tank\n",
        "            # Cylindrical tank\n",
        "            center_x, center_y = 112, 140\n",
        "            y, x = np.ogrid[:224, :224]\n",
        "            mask = (x - center_x)**2 + (y - center_y)**2 <= 50**2\n",
        "            img[mask] = [140, 140, 120]\n",
        "            \n",
        "        elif class_id == 3:  # Pipeline_Valve\n",
        "            # Horizontal pipe with valve\n",
        "            img[100:124, 50:174] = [100, 100, 120]  # Pipe\n",
        "            img[90:134, 100:124] = [80, 80, 100]    # Valve\n",
        "            \n",
        "        elif class_id == 4:  # Compressor_Station\n",
        "            # Rectangular building structure\n",
        "            img[80:160, 60:164] = [120, 120, 100]\n",
        "            \n",
        "        elif class_id == 5:  # Flare_Stack\n",
        "            # Tall vertical stack\n",
        "            img[20:180, 108:116] = [80, 80, 80]\n",
        "            # Flame at top\n",
        "            img[20:40, 104:120] = [255, 100, 0]\n",
        "            \n",
        "        elif class_id == 6:  # Separator_Vessel\n",
        "            # Horizontal cylindrical vessel\n",
        "            img[90:134, 40:184] = [130, 130, 110]\n",
        "            \n",
        "        elif class_id == 7:  # Control_Panel\n",
        "            # Rectangular panel with indicators\n",
        "            img[70:154, 70:154] = [60, 60, 80]\n",
        "            # Add some indicator lights\n",
        "            img[90:100, 90:100] = [0, 255, 0]  # Green light\n",
        "            img[90:100, 120:130] = [255, 0, 0]  # Red light\n",
        "        \n",
        "        # Add noise and variations\n",
        "        noise = np.random.normal(0, 10, img.shape)\n",
        "        img = np.clip(img.astype(np.float32) + noise, 0, 255).astype(np.uint8)\n",
        "        \n",
        "        return img\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        # Convert to PIL Image for transforms\n",
        "        image = Image.fromarray(image)\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, label\n",
        "\n",
        "# Create transforms (ImageNet normalization)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create dataset\n",
        "full_dataset = SyntheticEquipmentDataset(model_manager, samples_per_class=100)\n",
        "\n",
        "# Split dataset\n",
        "total_size = len(full_dataset)\n",
        "train_size = int(0.7 * total_size)\n",
        "val_size = int(0.15 * total_size)\n",
        "test_size = total_size - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    full_dataset, [train_size, val_size, test_size],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "# Apply transforms\n",
        "train_dataset.dataset.transform = train_transform\n",
        "val_dataset.dataset.transform = val_transform\n",
        "test_dataset.dataset.transform = val_transform\n",
        "\n",
        "print(f'✓ Dataset created and split:')\n",
        "print(f'• Training: {len(train_dataset)} samples')\n",
        "print(f'• Validation: {len(val_dataset)} samples')\n",
        "print(f'• Test: {len(test_dataset)} samples')\n",
        "print(f'• Classes: {list(model_manager.class_names.values())}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary & Validation\n",
        "\n",
        "This is a simplified version of Experiment 7 for testing. The complete implementation would include model training, comparison, and deployment optimization.\n",
        "\n",
        "**Key Components Demonstrated:**\n",
        "\n",
        "- Transfer learning theory and pre-trained model advantages\n",
        "- Multiple architecture support (ResNet, EfficientNet, MobileNet, ViT)\n",
        "- Different fine-tuning strategies (feature extraction, fine-tuning, full training)\n",
        "- Synthetic oil & gas equipment image generation\n",
        "- ImageNet normalization and data augmentation\n",
        "\n",
        "**Next Steps:**\n",
        "\n",
        "- Implement training loops for different transfer learning strategies\n",
        "- Add model comparison and performance benchmarking\n",
        "- Include efficiency analysis (inference time, model size, accuracy)\n",
        "- Implement model optimization for edge deployment\n",
        "- Add comprehensive evaluation and visualization tools\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "O_G_Kernel",
      "language": "python",
      "name": "o_g_kernel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
