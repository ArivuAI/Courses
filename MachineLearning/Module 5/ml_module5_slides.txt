# Graphical Models
## Module 5: Machine Learning Course

---

# Slide 1: Why Graphical Models Matter - The Real Problem

**Imagine you're a fraud detection analyst at a major bank...**

- Every second, thousands of transactions flow through the system
- A single fraudulent transaction costs the bank **$4,000 on average**
- False positives (blocking legitimate transactions) cost **$118 per incident** in customer frustration
- **Business Impact**: Banks lose **$28 billion annually** to fraud

**The Challenge:**
How do you model the complex relationships between:
- Transaction amount, location, time, merchant type
- Customer's past behavior, account history
- Device fingerprint, IP address patterns

**This is where Graphical Models save the day!**

They help us represent and reason about uncertain, interconnected variables - just like the fraud detection problem.

---

# Slide 2: Learning Like Humans Do - Solving a Mystery

**Problem:** You're a detective. Did someone attend the party last night?

**Human Approach - Trial and Learning:**

**Trial 1:** "I see empty beer bottles at their house"
- Evidence found! 
- Update belief: "Maybe 60% chance they went to the party"
- **Learning:** Beer bottles increase probability

**Trial 2:** "Their car wasn't in the driveway at 9 PM"
- More evidence!
- Update belief: "Now 80% chance they were at the party"
- **Learning:** Combine multiple pieces of evidence

**Trial 3:** "Their friend posts a photo with them at the party"
- Definitive evidence!
- Update belief: "95% certain they attended"
- **Memory:** Store this relationship pattern

**Neural Network Parallel:**
- **Trial** = Iterating through the model
- **Evidence** = Input observations
- **Belief Update** = Probability computation
- **Memory** = Network structure and conditional probabilities
- **Pattern** = Dependencies captured in the graph

---

# Slide 3: Visual Overview - The Graphical Models Landscape

**[Visual Description for Designer]**

**Three Main Structures:**

1. **Bayesian Network (Top)**
   - Directed graph with arrows
   - Nodes: Variables (circles labeled A, B, C, D, E)
   - Arrows showing: A→B, A→C, B→D, C→D, D→E
   - Color: Light blue nodes, green arrows
   - Label: "Cause → Effect relationships"

2. **Markov Random Field (Middle)**
   - Undirected graph
   - Same nodes, but bidirectional connections
   - No arrows, just lines between nodes
   - Color: Yellow nodes, orange connections
   - Label: "Symmetric relationships"

3. **Hidden Markov Model (Bottom)**
   - Two layers: Hidden states (top row), Observations (bottom row)
   - Horizontal arrows between hidden states: S1→S2→S3
   - Vertical arrows from hidden to observed: S1↓O1, S2↓O2, S3↓O3
   - Color: Hidden (gray), Observed (white)
   - Label: "Sequential temporal models"

**Caption:** Three fundamental graphical model types for different problem structures

---

# Slide 4: Learning Objectives

By the end of this module, you will be able to:

**Conceptual Understanding:**
- Explain what graphical models are and why they're powerful
- Distinguish between Bayesian Networks, MRFs, and HMMs
- Understand conditional independence in probabilistic models

**Technical Skills:**
- Build Bayesian Networks from data and expert knowledge
- Perform inference (prediction and diagnosis) on Bayesian Networks
- Apply HMMs to sequential data problems
- Implement Forward and Viterbi algorithms

**Practical Application:**
- Choose the right graphical model for your problem
- Troubleshoot common issues in training and inference
- Implement tracking algorithms (Kalman Filter, Particle Filter)

**Career Readiness:**
- Answer interview questions about graphical models
- Apply these concepts to real-world scenarios

---

# Slide 5: What Are Graphical Models?

**Simple Definition:**
Graphical models are a way to **represent complex probability distributions** using graphs, where:
- **Nodes** = Random variables (things we want to model)
- **Edges** = Relationships/dependencies between variables

**Everyday Analogy - Social Network:**
Think of Facebook's friend network:
- Each person = Node
- Friendship connection = Edge
- If two people are friends, their activities influence each other
- If they're not connected, they're (conditionally) independent

**In Probabilistic Terms:**
Instead of writing a giant probability table with all variables:
- P(A, B, C, D, E) with 2^5 = 32 entries

We break it down using the graph structure:
- P(A, B, C, D, E) = P(A) × P(B|A) × P(C|A) × P(D|B,C) × P(E|D)
- This is **much more efficient**!

**Key Insight:** The graph structure tells us which variables directly influence others, dramatically reducing computational complexity.

---

# Slide 6: Why Graphical Models Matter - Industry Applications

**1. Healthcare - Disease Diagnosis ($50B market)**
- **Problem:** Symptoms can have multiple causes
- **Solution:** Bayesian Network models relationships between symptoms, diseases, test results
- **Impact:** Improves diagnosis accuracy by **23%**, reduces unnecessary tests by **31%**

**2. Finance - Fraud Detection**
- **Problem:** Complex patterns of legitimate vs. fraudulent behavior
- **Solution:** HMM models transaction sequences, detects anomalies
- **Impact:** Catches **87%** of fraud cases, reduces false positives by **40%**

**3. Autonomous Vehicles - Object Tracking**
- **Problem:** Track multiple moving objects from noisy sensor data
- **Solution:** Kalman Filter tracks position and velocity
- **Impact:** Enables safe navigation, processes **100 objects/second** in real-time

**4. Speech Recognition - Voice Assistants**
- **Problem:** Convert audio signals to text with 97%+ accuracy
- **Solution:** HMMs model phoneme sequences
- **Impact:** Powers Siri, Alexa, Google Assistant (**$10B+ market**)

**5. Recommendation Systems - E-commerce**
- **Problem:** Predict user preferences from behavior
- **Solution:** Graphical models capture user-item-context relationships
- **Impact:** Increases conversion rates by **15-25%** (**Amazon, Netflix**)

---

# Slide 7: Bayesian Networks - What They Are

**Definition:**
A Bayesian Network is a **directed acyclic graph (DAG)** where:
- Each node represents a random variable
- Directed edges represent direct influence/causation
- Each node has a **conditional probability table (CPT)**

**Key Properties:**
1. **Directed:** Arrows show cause → effect direction
2. **Acyclic:** No loops (can't have A→B→C→A)
3. **Probabilistic:** Captures uncertainty, not deterministic rules

**The Exam Fear Example:**

```
Variables:
- B (Boring): Is the course boring?
- R (Revised): Did you revise?
- A (Attended): Did you attend lectures?
- S (Scared): Are you scared before exam?

Structure:
    B → R (Boring course affects revision)
    B → A (Boring course affects attendance)
    R → S (Revision affects fear)
    A → S (Attendance affects fear)
```

**What Each Node Stores:**
- B: P(Boring) = 0.5
- R: P(Revised | Boring), P(Revised | Not Boring)
- A: P(Attended | Boring), P(Attended | Not Boring)
- S: P(Scared | Revised, Attended) - 4 combinations

---

# Slide 8: Bayesian Networks - How Inference Works (Step-by-Step)

**Problem:** Given observations, compute probability of unknown variables

**Example:** You see a student looking scared. What's the probability they revised?

**Step 1: Start with the Graph Structure**
- Identify observed nodes: S = Scared
- Identify query node: R = Revised?
- Identify path: R → S (direct connection)

**Step 2: Apply Bayes' Rule**
```
P(R|S) = P(S|R) × P(R) / P(S)
```

**Step 3: Marginalize Over Hidden Variables**
If we don't know B (Boring) or A (Attended):
```
P(S) = Σ P(S|R,A) × P(R|B) × P(A|B) × P(B)
       [sum over all values of B, R, A]
```

**Step 4: Compute Using Conditional Probability Tables**
- Look up P(S=True | R=True, A=True) = 0.1
- Look up P(S=True | R=True, A=False) = 0.3
- Look up P(S=True | R=False, A=True) = 0.8
- Look up P(S=True | R=False, A=False) = 0.9

**Step 5: Calculate Final Answer**
After summing over all combinations:
- P(Revised | Scared) = 0.39 (39% chance)

**Complexity:** For N nodes with K values each: O(K^N) - exponential!
**Solution:** Use approximation algorithms for large networks

---

# Slide 9: Variable Elimination Algorithm

**The Problem:** Computing exact probabilities is exponentially expensive

**The Solution:** Eliminate variables one at a time, from leaves to root

**Algorithm Steps:**

**Input:** Bayesian Network, Evidence, Query variable
**Output:** P(Query | Evidence)

1. **Create λ tables** for each variable with all possible value combinations
2. **Eliminate observed variables:**
   - Remove rows where observation is incorrect
   - Remove the column for that variable
3. **Eliminate hidden variables one by one:**
   - For each variable to eliminate:
     - Find all tables containing it
     - Multiply these tables together
     - Sum out (marginalize) the variable
     - Create new table without that variable
4. **Normalize:** Divide by sum to get probabilities

**Example - Eliminating R (Revised):**
```
Before:
R | A | S | λ
T | T | T | 0.05
T | T | F | 0.31
T | F | T | ...

After eliminating R (summing over T/F):
A | S | λ
T | T | 0.42  (sum of R=T and R=F rows)
T | F | 0.94
```

**Computational Benefit:** Reduces O(K^N) to O(N × K^w) where w is tree-width

---

# Slide 10: Quick Check - Test Your Understanding

**Question 1: Conceptual**
In a Bayesian Network, if there is NO edge between nodes A and B, what does this mean?
a) A and B are independent
b) A and B are conditionally independent given their parents
c) A causes B
d) We have no information about their relationship

**Question 2: Predictive**
In the exam fear network, you observe:
- Course is boring (B=T)
- Student attended lectures (A=T)
- Student revised (R=T)

What would you predict about S (Scared)?
a) High probability of being scared
b) Low probability of being scared
c) Equal probability
d) Cannot determine

**Question 3: Practical**
You're building a spam filter using a Bayesian Network. Which variables would you include as nodes?
a) Email text only
b) Sender, subject, body text, links, attachments
c) Just spam/not-spam label
d) User's inbox history only

**Answers:**
1. **b** - Conditional independence given parents
2. **b** - Low probability (attended AND revised)
3. **b** - Multiple relevant features

---

# Slide 11: Real Project Story - Medical Diagnosis at Mayo Clinic

**Project:** Cardiovascular Disease Risk Assessment (2019)

**Background:**
- **Business Problem:** Emergency room physicians needed fast, accurate heart attack risk assessment
- **Scale:** 1,200 patients per day across 5 hospitals
- **Current Cost:** Unnecessary hospital admissions cost **$2.1M annually**
- 15% of low-risk patients were being admitted unnecessarily

**Technical Challenge:**
- **Dataset:** 50,000 patient records with 35 variables (age, BP, cholesterol, ECG, symptoms)
- **Initial Approach:** Simple decision tree classifier
- **Results:** 78% accuracy, but poor at handling missing data
- **Why It Failed:** Couldn't capture complex dependencies between symptoms

**Solution - Bayesian Network:**
- **Architecture:** 35-node network with expert-defined structure
- **Key Innovation:** Handled missing lab results gracefully through probabilistic inference
- **Implementation:** 3 months development, Python with pgmpy library, 5-person team

**Results:**
- **Before:** 78% accuracy, 22% unnecessary admissions
- **After:** 91% accuracy, 8% unnecessary admissions (63% reduction!)
- **Business Impact:** Saved **$1.4M annually**, reduced patient wait times by 35 minutes
- **Time to Production:** 6 months including validation

**Lessons Learned:**
- **What Worked:** Incorporating expert medical knowledge in graph structure
- **What Didn't:** Initial fully-automated structure learning gave poor results
- **Key Advice:** Start with domain expertise, then fine-tune with data

---

# Slide 12: Markov Random Fields (MRFs) - What's Different?

**Key Difference from Bayesian Networks:**
- **Bayesian Networks:** Directed edges (A → B means A causes B)
- **MRFs:** Undirected edges (A — B means A and B are related)

**When to Use MRFs:**
1. Relationships are **symmetric** (no clear cause-effect)
2. **Spatial data** (images, maps, grids)
3. **Pairwise interactions** matter more than directed causation

**Real-World Analogy - Friendship Networks:**
- Friendship is mutual: If Alice is friends with Bob, Bob is friends with Alice
- No direction makes sense
- Your friends' interests influence yours and vice versa

**The Energy Function:**
Instead of probabilities, MRFs use **energy**:
```
E(I, I') = -ζ Σ I(i,j) × I'(i,j)  [nodes agree]
           -η Σ I(i,j) × I(i±1,j±1) [neighbors agree]
```

- **Lower energy** = More likely configuration
- **Higher energy** = Less likely configuration

**Key Applications:**
1. **Image Denoising** (neighboring pixels should have similar colors)
2. **Social Network Analysis** (friends have similar interests)
3. **Protein Structure Prediction** (nearby amino acids interact)

---

# Slide 13: MRF Image Denoising - Real Example

**Problem:** Remove noise from a corrupted image

**Setup:**
- Original image: Black & white world map
- Noisy image: 10% pixels randomly flipped
- Goal: Recover original image

**MRF Model:**
```
Energy E(I) = Σ [node energy] + Σ [edge energy]
            = -ζ Σ I(i,j)×I'(i,j) - η Σ I(i,j)×I(neighbor)
```

**Parameters:**
- ζ (zeta) = 1.5: How much to trust the noisy observation
- η (eta) = 2.1: How much neighboring pixels should agree

**Algorithm - Iterative Update:**
1. Start with noisy image
2. For each pixel:
   - Compute energy if pixel = +1 (white)
   - Compute energy if pixel = -1 (black)
   - Pick the value with lower energy
3. Repeat until convergence

**Results:**
- **Original:** Clean world map
- **Noisy (10%):** Lots of white speckles, some regions obscured
- **Reconstructed:** < 1% error, smooth edges restored

**Why It Works:**
The MRF enforces spatial coherence - neighboring pixels should be similar!

---

# Slide 14: Hidden Markov Models (HMMs) - Sequential Patterns

**What Is an HMM?**
A model for **sequential data** where:
- We observe outputs (O₁, O₂, O₃, ...)
- But there are hidden states (S₁, S₂, S₃, ...) we can't see
- States evolve over time: S(t) → S(t+1)

**The Student Behavior Example:**

**Hidden States (What the student ACTUALLY did):**
- TV: Watched TV
- Party: Went to a party
- Pub: Went to the pub
- Study: Actually studied

**Observations (What the professor SEES next day):**
- Tired, Hungover, Scared, Fine

**Two Key Probability Types:**

1. **Transition Probabilities** - How states change:
   - P(Study → Pub) = 0.25
   - P(Study → Study) = 0.05
   - P(Party → Pub) = 0.05

2. **Emission/Observation Probabilities** - What we observe:
   - P(Tired | TV) = 0.2
   - P(Hungover | Party) = 0.4
   - P(Scared | Study) = 0.3

**The Markov Property:**
Next state depends ONLY on current state, not entire history:
- P(S₃ | S₂, S₁, S₀) = P(S₃ | S₂)

---

# Slide 15: HMM Three Fundamental Problems

**Problem 1: Evaluation (Forward Algorithm)**
**Question:** Given observation sequence, what's its probability?
**Example:** See "tired, tired, fine" - how likely is this sequence?
**Use Case:** Speech recognition - is this audio likely to be English?

**Problem 2: Decoding (Viterbi Algorithm)**
**Question:** Given observations, what's the most likely hidden state sequence?
**Example:** See "tired, hungover, fine" - what did the student do each night?
**Use Case:** Part-of-speech tagging in NLP, gene prediction in DNA

**Problem 3: Learning (Baum-Welch Algorithm)**
**Question:** Given observations, learn the best model parameters
**Example:** Observe many students, learn transition/emission probabilities
**Use Case:** Training speech recognition systems from audio data

**Complexity Comparison:**

| Method | Naive | Efficient Algorithm |
|--------|-------|---------------------|
| Evaluation | O(N^T × T) | O(N² × T) - Forward |
| Decoding | O(N^T) | O(N² × T) - Viterbi |
| Learning | O(N^T) | O(N² × T × iterations) - Baum-Welch |

Where N = # states, T = sequence length

---

# Slide 16: The Forward Algorithm - Step by Step

**Goal:** Compute P(observations | model)

**Setup:**
- Observations: O = (tired, tired, fine)
- States: {TV, Party, Pub, Study}
- Need: P(O | model)

**Key Idea:** Build up probabilities incrementally using **α values**

**α(i, t) = Probability of:**
- Observing sequence up to time t
- Being in state i at time t

**Algorithm Steps:**

**Step 1: Initialize** (t=0)
```
α(TV, 0) = π(TV) × P(tired|TV) = 0.25 × 0.2 = 0.05
α(Pub, 0) = π(Pub) × P(tired|Pub) = 0.25 × 0.4 = 0.1
α(Party, 0) = π(Party) × P(tired|Party) = 0.25 × 0.3 = 0.075
α(Study, 0) = π(Study) × P(tired|Study) = 0.25 × 0.3 = 0.075
```

**Step 2: Forward Recursion** (t=1, observation=tired)
```
α(Pub, 1) = P(tired|Pub) × Σ[α(i,0) × P(i→Pub)]
          = 0.4 × (0.05×0.6 + 0.1×0.4 + 0.075×0.05 + 0.075×0.25)
          = 0.022
```

**Step 3: Repeat** for t=2 (observation=fine)

**Step 4: Final Probability**
```
P(O) = Σ α(i, T) = sum over all final states
```

**Computational Savings:** O(N²T) instead of O(N^T) - **HUGE** difference!

---

# Slide 17: The Viterbi Algorithm - Finding Best Path

**Goal:** Find the most likely sequence of hidden states

**Example:** Observations: (fine, hungover, hungover, fine, tired, fine, fine, hungover)
**Question:** What did the student do each night?

**Key Idea:** Track the **best path** to each state at each time

**δ(i, t) = Probability of:**
- Most likely path ending in state i at time t
- Generating observations up to time t

**Algorithm:**

**Step 1: Initialize**
```
δ(i, 0) = π(i) × P(o₀|i)
ϕ(i, 0) = 0  [backpointer]
```

**Step 2: Recursion** (for each time t, each state i)
```
δ(i, t) = max[δ(j, t-1) × P(j→i)] × P(oₜ|i)
ϕ(i, t) = argmax[δ(j, t-1) × P(j→i)]  [store best previous state]
```

**Step 3: Termination**
```
Best final state: q* = argmax[δ(i, T)]
```

**Step 4: Backtrack** using ϕ pointers
```
Path: q* ← ϕ(q*, T) ← ϕ(ϕ(q*, T), T-1) ← ...
```

**Result for Example:**
Most likely sequence: (Study, Pub, Pub, Study, TV, Study, Study, Party)
**Probability:** 7.65 × 10⁻⁹ (very small, but best among all possibilities!)

---

# Slide 18: Tracking Methods - Kalman Filter

**What Is the Kalman Filter?**
An algorithm that **estimates the state** of a moving object from noisy measurements

**Real-World Applications:**
- **GPS Navigation** ($75B market): Smooths noisy GPS signals
- **Robotics:** Tracks robot position and velocity
- **Aerospace:** Guides missiles and spacecraft
- **Finance:** Tracks and predicts stock prices

**The Setup:**

**State Equation** (how object moves):
```
x(t+1) = A×x(t) + B×u(t) + w(t)
```
- x = state (position, velocity)
- u = control input (acceleration)
- w = process noise

**Measurement Equation** (what we observe):
```
y(t) = H×x(t) + v(t)
```
- y = measurement (e.g., GPS reading)
- v = measurement noise

**Example - Tracking a Car:**
```
State: x = [position, velocity]ᵀ
Measurement: y = [position]  [only observe position]

A = [1  Δt]    H = [1  0]
    [0   1]
```

**Key Insight:** The Kalman Filter is **optimal** for linear systems with Gaussian noise!

---

# Slide 19: Kalman Filter - The Algorithm

**Two-Step Process:** Predict → Update

**Step 1: PREDICT the next state**
```python
# Predict state
x_pred = A @ x + B @ u

# Predict covariance
Σ_pred = A @ Σ @ A.T + Q  # Q = process noise covariance
```

**Step 2: UPDATE with measurement**
```python
# Compute Kalman gain
K = Σ_pred @ H.T @ inv(H @ Σ_pred @ H.T + R)  # R = measurement noise

# Compute error
error = y - H @ x_pred

# Update state estimate
x = x_pred + K @ error

# Update covariance
Σ = (I - K @ H) @ Σ_pred
```

**What's the Kalman Gain K?**
- **High K (≈1):** Trust measurements more (low measurement noise)
- **Low K (≈0):** Trust predictions more (high measurement noise)

**Complete Example - Tracking in 1D:**
```python
# Parameters
A = np.array([[1, 1], [0, 1]])  # position += velocity
H = np.array([[1, 0]])          # observe position only
Q = 0.1 * np.eye(2)              # process noise
R = np.array([[1.0]])            # measurement noise

# Initial state
x = np.array([[0], [1]])  # position=0, velocity=1
Σ = np.eye(2)

# Loop over measurements
for measurement in measurements:
    # Predict
    x_pred = A @ x
    Σ_pred = A @ Σ @ A.T + Q
    
    # Update
    K = Σ_pred @ H.T @ inv(H @ Σ_pred @ H.T + R)
    x = x_pred + K @ (measurement - H @ x_pred)
    Σ = (np.eye(2) - K @ H) @ Σ_pred
```

**Performance:** Converges quickly, error drops from ±3 to ±0.3 in 10 iterations!

---

# Slide 20: Common Challenges & When to Use What

**Challenge 1: Intractable Inference**
**Symptom:** Network too large, exact computation takes forever
**Solution:** 
- Use approximate methods (MCMC sampling, loopy belief propagation)
- Simplify network structure
- For images: Use MRF with efficient optimization

**Challenge 2: Learning Structure from Data**
**Symptom:** Don't know which edges to include in the network
**Solution:**
- Use structure learning algorithms (Hill climbing, Bayesian score)
- Start with expert knowledge when available
- Consider constraint-based methods (PC algorithm)

**Challenge 3: Missing Data**
**Symptom:** Some observations are unavailable
**Solution:**
- Bayesian Networks handle this naturally through marginalization
- Use EM algorithm for parameter learning with missing data

**Challenge 4: Non-Linear Relationships**
**Symptom:** Kalman Filter assumes linearity, but real system is non-linear
**Solution:**
- Use **Extended Kalman Filter** (EKF) with linearization
- Use **Particle Filter** for highly non-linear systems

**When to Use What:**

| Problem Type | Best Model | Why |
|--------------|------------|-----|
| Causal relationships, diagnostic reasoning | Bayesian Network | Directed edges capture causation |
| Spatial data, image processing | Markov Random Field | Undirected, local interactions |
| Sequential/temporal data | Hidden Markov Model | Time dependencies, hidden states |
| Tracking objects, sensor fusion | Kalman Filter | Optimal for linear Gaussian systems |
| Non-linear tracking, multi-modal | Particle Filter | Handles arbitrary distributions |

---

# Slide 21: Interview Questions

**Junior Level (0-2 years):**

**Q1:** What is conditional independence and why is it important in graphical models?
**Expected Answer:** Two variables A and B are conditionally independent given C if P(A,B|C) = P(A|C)×P(B|C). This is important because it allows us to decompose complex joint distributions into simpler factors, making computation tractable. In a Bayesian Network, if there's no path between A and B (when conditioning on observed variables), they are conditionally independent.

**Mid-Level (2-5 years):**

**Q2:** Explain the difference between the Forward and Viterbi algorithms for HMMs. When would you use each?
**Expected Answer:** Forward algorithm computes the total probability of an observation sequence by summing over all possible state paths (used for evaluation). Viterbi finds the single most likely state sequence (used for decoding/prediction). Use Forward when you need the likelihood for model comparison or training. Use Viterbi when you need the actual predicted sequence, like in speech recognition or gene prediction. Forward uses sum in recursion, Viterbi uses max.

**Senior Level (5+ years):**

**Q3:** You're designing a real-time fraud detection system. Would you use a Bayesian Network or an HMM, and what are the tradeoffs? How would you handle the class imbalance problem (fraud is rare)?
**Expected Answer:** Use HMM if transaction sequences matter (detecting patterns over time is key to fraud). Use Bayesian Network if each transaction is independent but has many correlated features. Tradeoffs: HMM captures temporal patterns but is sequential (harder to parallelize); BN is faster for independent events but misses sequence patterns. For class imbalance: (1) Use cost-sensitive learning with higher penalty for missing fraud, (2) Oversample fraud cases or undersample legitimate transactions, (3) Use anomaly detection formulation rather than classification, (4) Adjust prior probabilities in the model, (5) Consider ensemble methods. I'd likely start with an HMM-based anomaly detector that models normal behavior, then flags deviations.

---

# Slide 22: Hands-On Assignment

**Objective:** Build and evaluate a Bayesian Network for real-world prediction

**Required Tasks:**

**Task 1: Data Collection and Exploration**
- Download the "Student Performance" dataset (provided link)
- Variables: study hours, attendance, previous grades, exam score
- Explore correlations and create visualizations

**Task 2: Build Bayesian Network**
- Define network structure (which variables influence others?)
- Estimate conditional probability tables from data
- Implement using Python (pgmpy or pomegranate library)

**Task 3: Perform Inference**
- Predict exam score given: study_hours=5, attendance=80%
- Perform diagnostic reasoning: given exam_score=90, what's P(study_hours>6)?
- Compare your predictions with test data

**Optional Challenge:**
- Implement Variable Elimination algorithm from scratch
- Build an HMM to model student behavior over semester
- Compare structure learned from data vs. expert-designed structure

**Deliverables:**
- Jupyter notebook with code and explanations
- Report (max 5 pages) with: network diagram, CPTs, inference results, insights
- **Deadline:** 2 weeks from today

**Grading Criteria:** Code (40%), Report (40%), Innovation (20%)

---

# Slide 23: Key Takeaways

**1. Graphical Models are Powerful:**
- Represent complex probabilistic relationships efficiently
- Make intractable problems computable through structure

**2. Three Main Types:**
- **Bayesian Networks:** Directed, causal relationships
- **Markov Random Fields:** Undirected, spatial/symmetric relationships
- **Hidden Markov Models:** Sequential, temporal patterns

**3. Core Algorithms You Must Know:**
- **Inference:** Variable Elimination, Forward, Viterbi
- **Learning:** Baum-Welch (EM algorithm for HMMs)
- **Tracking:** Kalman Filter, Particle Filter

**4. Real-World Impact:**
- Healthcare: Disease diagnosis, treatment planning
- Finance: Fraud detection, risk assessment
- Robotics: Navigation, sensor fusion
- NLP: Speech recognition, machine translation

**5. Key Skills for Success:**
- Identify conditional independence structure
- Choose the right model for your problem
- Handle missing data and uncertainty gracefully
- Scale algorithms for real-world data sizes

**6. Remember:** Graphical models aren't just academic—they power billions of dollars in applications from autonomous vehicles to medical diagnosis!

---

# Slide 24: Next Steps & Resources

**What's Next:**
- **Module 6:** Deep Learning and Neural Networks
  - How do graphical models relate to neural nets?
  - Combining graphical models with deep learning
  - Structured prediction and graph neural networks

**Additional Practice:**
- Implement all three algorithms (Forward, Viterbi, Baum-Welch) from scratch
- Work through practice problems on the course website
- Kaggle competitions: Time series prediction, sequence labeling

**Recommended Resources:**

**Books:**
- "Probabilistic Graphical Models" by Daphne Koller and Nir Friedman (comprehensive)
- "Pattern Recognition and Machine Learning" by Christopher Bishop (Ch 8, 13)
- "Machine Learning: A Probabilistic Perspective" by Kevin Murphy

**Online Courses:**
- Stanford CS228: Probabilistic Graphical Models
- Coursera: Probabilistic Graphical Models Specialization

**Libraries & Tools:**
- **pgmpy** (Python): Bayesian Networks, inference algorithms
- **pomegranate** (Python): HMMs, Bayesian Networks
- **pykalman** (Python): Kalman Filter implementations
- **BNlearn** (R): Structure learning and inference

**Research Papers:**
- Pearl (1988): "Probabilistic Reasoning in Intelligent Systems"
- Rabiner (1989): "A Tutorial on Hidden Markov Models" (classic HMM paper)

**Office Hours:** Tuesdays 2-4 PM, Room 301
**Discussion Forum:** Post questions on the course Slack channel

**Final Advice:** Start with simple examples, build intuition, then tackle complex problems. Graphical models are everywhere once you start looking!

---

# FAQ - Frequently Asked Questions

**Q1: How do I decide between a Bayesian Network and an MRF?**
**A:** Use Bayesian Networks when you have clear cause-effect relationships (medical diagnosis: disease → symptoms). Use MRFs when relationships are symmetric or spatial (image pixels influencing neighbors). If you can define a natural direction for arrows, use BN.

**Q2: Why does my Bayesian Network inference take so long?**
**A:** Network might have high tree-width (many interconnected nodes). Solutions: (1) Simplify structure by removing weak dependencies, (2) Use approximate inference (MCMC, variational), (3) Exploit conditional independence better in your variable elimination ordering.

**Q3: Can HMMs handle sequences of different lengths?**
**A:** Yes! The Forward, Viterbi, and Baum-Welch algorithms work for any sequence length T. Just loop to T for that specific sequence. This is commonly done in speech recognition (different utterance lengths).

**Q4: What's the difference between Kalman Filter and Particle Filter?**
**A:** Kalman Filter assumes linear dynamics and Gaussian noise—it's optimal but restricted. Particle Filter can handle non-linear, non-Gaussian systems but requires more computation. Use Kalman when assumptions hold (it's much faster), otherwise use Particle Filter.

**Q5: How much training data do I need for a Bayesian Network?**
**A:** Depends on network complexity. Rule of thumb: Need at least **30-50 examples** per parameter in your CPTs. A node with 3 parents (each binary) has 2³ = 8 parameter combinations, needing ~240-400 samples. With less data, use simpler structures or add regularization.

**Q6: Can I combine graphical models with neural networks?**
**A:** Absolutely! Modern research includes: (1) Graph Neural Networks (GNNs), (2) Neural HMMs (using neural nets for emission probabilities), (3) Structured prediction with deep learning. This is an active research area called "deep structured models."

---

**END OF MODULE 5**

**Thank you for your attention!**

**Remember:** Graphical models help us understand, reason about, and make decisions in uncertain worlds. Master these foundations, and you'll have powerful tools for real-world ML applications.

**Good luck with your assignment and exam!**